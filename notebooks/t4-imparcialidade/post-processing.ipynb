{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbe0e291-49a0-496e-b3b0-5618e391f467",
   "metadata": {},
   "source": [
    "# Post-processing techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dd0b81-084d-4f3b-8c56-f8e66ecfa8a7",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bee5861f-5923-400a-ab7e-0c52280e00dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0386785f-5689-451c-a00b-15279b0ab279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>faves_pca0</th>\n",
       "      <th>faves_pca1</th>\n",
       "      <th>unfaves_pca0</th>\n",
       "      <th>unfaves_pca1</th>\n",
       "      <th>accessories</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>animamted</th>\n",
       "      <th>...</th>\n",
       "      <th>Drama.2</th>\n",
       "      <th>Entertainment (Variety Shows)</th>\n",
       "      <th>Factual</th>\n",
       "      <th>Learning</th>\n",
       "      <th>Music</th>\n",
       "      <th>News</th>\n",
       "      <th>Religion &amp;amp; Ethics</th>\n",
       "      <th>Sport.1</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Rating_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321485</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>-0.19967</td>\n",
       "      <td>-0.200645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321485</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>-0.19967</td>\n",
       "      <td>-0.200645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321485</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>-0.19967</td>\n",
       "      <td>-0.200645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321485</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>-0.19967</td>\n",
       "      <td>-0.200645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321485</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>-0.19967</td>\n",
       "      <td>-0.200645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 515 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Age  Income  faves_pca0  faves_pca1  unfaves_pca0  \\\n",
       "0           0   62       1   -0.321485      0.0786      -0.19967   \n",
       "1           1   62       1   -0.321485      0.0786      -0.19967   \n",
       "2           2   62       1   -0.321485      0.0786      -0.19967   \n",
       "3           3   62       1   -0.321485      0.0786      -0.19967   \n",
       "4           4   62       1   -0.321485      0.0786      -0.19967   \n",
       "\n",
       "   unfaves_pca1  accessories  alcohol  animamted  ...  Drama.2  \\\n",
       "0     -0.200645          0.0      0.0        0.0  ...        1   \n",
       "1     -0.200645          0.0      0.0        0.0  ...        1   \n",
       "2     -0.200645          0.0      0.0        0.0  ...        1   \n",
       "3     -0.200645          0.0      0.0        0.0  ...        1   \n",
       "4     -0.200645          0.0      0.0        0.0  ...        1   \n",
       "\n",
       "   Entertainment (Variety Shows)  Factual  Learning  Music  News  \\\n",
       "0                              0        0         0      0     0   \n",
       "1                              0        0         0      0     0   \n",
       "2                              0        0         0      0     0   \n",
       "3                              0        0         0      0     0   \n",
       "4                              0        0         0      0     0   \n",
       "\n",
       "   Religion &amp; Ethics  Sport.1  Weather  Rating_bin  \n",
       "0                      0        0        0           0  \n",
       "1                      0        0        0           0  \n",
       "2                      0        0        0           0  \n",
       "3                      0        0        0           0  \n",
       "4                      0        0        0           0  \n",
       "\n",
       "[5 rows x 515 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/final_features_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4298340a-e65c-4c71-b161-6c8ed5d0a0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>faves_pca0</th>\n",
       "      <th>faves_pca1</th>\n",
       "      <th>unfaves_pca0</th>\n",
       "      <th>unfaves_pca1</th>\n",
       "      <th>accessories</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>animamted</th>\n",
       "      <th>animated</th>\n",
       "      <th>...</th>\n",
       "      <th>Comedy.1</th>\n",
       "      <th>Drama.2</th>\n",
       "      <th>Entertainment (Variety Shows)</th>\n",
       "      <th>Factual</th>\n",
       "      <th>Learning</th>\n",
       "      <th>Music</th>\n",
       "      <th>News</th>\n",
       "      <th>Religion &amp;amp; Ethics</th>\n",
       "      <th>Sport.1</th>\n",
       "      <th>Weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321485</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>-0.19967</td>\n",
       "      <td>-0.200645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321485</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>-0.19967</td>\n",
       "      <td>-0.200645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321485</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>-0.19967</td>\n",
       "      <td>-0.200645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321485</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>-0.19967</td>\n",
       "      <td>-0.200645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321485</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>-0.19967</td>\n",
       "      <td>-0.200645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Income  faves_pca0  faves_pca1  unfaves_pca0  unfaves_pca1  \\\n",
       "0   62       1   -0.321485      0.0786      -0.19967     -0.200645   \n",
       "1   62       1   -0.321485      0.0786      -0.19967     -0.200645   \n",
       "2   62       1   -0.321485      0.0786      -0.19967     -0.200645   \n",
       "3   62       1   -0.321485      0.0786      -0.19967     -0.200645   \n",
       "4   62       1   -0.321485      0.0786      -0.19967     -0.200645   \n",
       "\n",
       "   accessories  alcohol  animamted  animated  ...  Comedy.1  Drama.2  \\\n",
       "0          0.0      0.0        0.0       0.0  ...         1        1   \n",
       "1          0.0      0.0        0.0       0.0  ...         1        1   \n",
       "2          0.0      0.0        0.0       0.0  ...         1        1   \n",
       "3          0.0      0.0        0.0       0.0  ...         1        1   \n",
       "4          0.0      0.0        0.0       0.0  ...         1        1   \n",
       "\n",
       "   Entertainment (Variety Shows)  Factual  Learning  Music  News  \\\n",
       "0                              0        0         0      0     0   \n",
       "1                              0        0         0      0     0   \n",
       "2                              0        0         0      0     0   \n",
       "3                              0        0         0      0     0   \n",
       "4                              0        0         0      0     0   \n",
       "\n",
       "   Religion &amp; Ethics  Sport.1  Weather  \n",
       "0                      0        0        0  \n",
       "1                      0        0        0  \n",
       "2                      0        0        0  \n",
       "3                      0        0        0  \n",
       "4                      0        0        0  \n",
       "\n",
       "[5 rows x 512 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.fillna(0)\n",
    "y = df['Rating_bin']\n",
    "X = df.drop(columns=['Unnamed: 0', 'Rating_bin', 'Gender_F'])\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "398c3321-454c-4a02-a5a1-67a394c3902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42, train_size=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d2ae9d-929c-472e-9d60-a6cd6ab41b4b",
   "metadata": {},
   "source": [
    "## Baseline model: DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05e4c735-181a-4ff4-bb29-d90c55eb4e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.63      0.76      4635\n",
      "           1       0.26      0.77      0.39       783\n",
      "\n",
      "    accuracy                           0.65      5418\n",
      "   macro avg       0.60      0.70      0.57      5418\n",
      "weighted avg       0.84      0.65      0.70      5418\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2927, 1708],\n",
       "       [ 183,  600]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))\n",
    "confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dea1ae-1b43-4aa0-98a4-778c80968caa",
   "metadata": {},
   "source": [
    "## Métrica de fairness: Statistical Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f054787-323b-427d-91a7-f1acb8d2a75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def statistical_parity(y, y_, Z, priv=None):\n",
    "  if priv is None:\n",
    "    values = np.unique(Z)\n",
    "    counts = [np.mean(y[Z==z]) for z in values]\n",
    "    priv = values[np.argmax(counts)]\n",
    "    unpriv = [z for z in values if z != priv]\n",
    "  else:\n",
    "    unpriv = [z for z in values if z != priv]\n",
    "  \n",
    "  return np.array([np.mean([y_i for y_i, zi in zip(y_, Z) if zi == unp]) - np.mean([y_i for y_i, zi in zip(y_, Z) if zi == priv])\n",
    "                   for unp in unpriv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97e4372b-52c9-438d-8d2b-adf61d776dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train = X_train['Gender_M']==1\n",
    "Z_val = X_val['Gender_M']==1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210ba853-1521-42bb-b79c-e40a5b015d8b",
   "metadata": {},
   "source": [
    "## Desempenho do baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a301d04c-5ba4-46a9-8617-fc8e40d230f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.38822387576835976\n",
      "Statistical parity -0.030887433610065462\n"
     ]
    }
   ],
   "source": [
    "y_val_ = clf.predict(X_val)\n",
    "\n",
    "print('F1-score:', f1_score(y_val, y_val_))\n",
    "print('Statistical parity', statistical_parity(y_val, y_val_, Z_val)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f94d0f-4761-48cb-a204-15c02bf798fc",
   "metadata": {},
   "source": [
    "## Estratégia 1: Threshold Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0225ee6d-8ac2-4469-9866-d107a81d7fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.07556080283353012\n",
      "Statistical parity 0.00028360748723766337\n"
     ]
    }
   ],
   "source": [
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "\n",
    "postprocess_est = ThresholdOptimizer(\n",
    "                   estimator=clf,\n",
    "                   constraints=\"demographic_parity\",\n",
    "                   objective=\"accuracy_score\",\n",
    "                   prefit=True,\n",
    "                   predict_method='predict_proba')\n",
    "postprocess_est.fit(X_train, y_train, sensitive_features=Z_train)\n",
    "\n",
    "y_val_ = postprocess_est.predict(X_val, sensitive_features=Z_val)\n",
    "\n",
    "print('F1-score:', f1_score(y_val, y_val_))\n",
    "print('Statistical parity', statistical_parity(y_val, y_val_, Z_val)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2c2fae-3275-4740-8e72-83675d9df9d6",
   "metadata": {},
   "source": [
    "### Avaliando hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cdddc4-da99-477f-bb09-6990d8204c77",
   "metadata": {},
   "source": [
    "O ThresholdOptimizer possui dois hiperparâmetros que geram impacto direto nas métricas, são eles: `constraints` e `objective`. Avaliando os resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41eeed34-e1d0-41d2-a9a4-a141101310e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline F1: 0.38822387576835976\n",
      "Baseline statistical parity: -0.030887433610065462\n",
      "---\n",
      "Optimizing using objective \"accuracy_score\" and constraint \"demographic_parity\"\n",
      "F1-score: 0.06658739595719383\n",
      "Statistical parity: 0.0018305574176249156\n",
      "---\n",
      "Optimizing using objective \"balanced_accuracy_score\" and constraint \"demographic_parity\"\n",
      "F1-score: 0.3863709418193507\n",
      "Statistical parity: 0.008894962099726678\n",
      "---\n",
      "Optimizing using objective \"selection_rate\" and constraint \"demographic_parity\"\n",
      "F1-score: 0.2525399129172714\n",
      "Statistical parity: 0.0\n",
      "---\n",
      "Optimizing using objective \"true_positive_rate\" and constraint \"demographic_parity\"\n",
      "F1-score: 0.2525399129172714\n",
      "Statistical parity: 0.0\n",
      "---\n",
      "Optimizing using objective \"true_negative_rate\" and constraint \"demographic_parity\"\n",
      "F1-score: 0.0\n",
      "Statistical parity: 0.0\n",
      "---\n",
      "Optimizing using objective \"accuracy_score\" and constraint \"selection_rate_parity\"\n",
      "F1-score: 0.06183115338882283\n",
      "Statistical parity: 0.0026427061310782245\n",
      "---\n",
      "Optimizing using objective \"balanced_accuracy_score\" and constraint \"selection_rate_parity\"\n",
      "F1-score: 0.3875321336760925\n",
      "Statistical parity: 0.009178569586964336\n",
      "---\n",
      "Optimizing using objective \"selection_rate\" and constraint \"selection_rate_parity\"\n",
      "F1-score: 0.2525399129172714\n",
      "Statistical parity: 0.0\n",
      "---\n",
      "Optimizing using objective \"true_positive_rate\" and constraint \"selection_rate_parity\"\n",
      "F1-score: 0.2525399129172714\n",
      "Statistical parity: 0.0\n",
      "---\n",
      "Optimizing using objective \"true_negative_rate\" and constraint \"selection_rate_parity\"\n",
      "F1-score: 0.0\n",
      "Statistical parity: 0.0\n",
      "---\n",
      "Optimizing using objective \"accuracy_score\" and constraint \"equalized_odds\"\n",
      "F1-score: 0.0\n",
      "Statistical parity: 0.0\n",
      "---\n",
      "Optimizing using objective \"balanced_accuracy_score\" and constraint \"equalized_odds\"\n",
      "F1-score: 0.3862382343395001\n",
      "Statistical parity: 0.0003867374825967662\n",
      "---\n",
      "Optimizing using objective \"accuracy_score\" and constraint \"true_positive_rate_parity\"\n",
      "F1-score: 0.0\n",
      "Statistical parity: -0.0005285412262156448\n",
      "---\n",
      "Optimizing using objective \"balanced_accuracy_score\" and constraint \"true_positive_rate_parity\"\n",
      "F1-score: 0.3906915765322845\n",
      "Statistical parity: -0.009745784561439652\n",
      "---\n",
      "Optimizing using objective \"selection_rate\" and constraint \"true_positive_rate_parity\"\n",
      "F1-score: 0.2525399129172714\n",
      "Statistical parity: 0.0\n",
      "---\n",
      "Optimizing using objective \"true_positive_rate\" and constraint \"true_positive_rate_parity\"\n",
      "F1-score: 0.2525399129172714\n",
      "Statistical parity: 0.0\n",
      "---\n",
      "Optimizing using objective \"true_negative_rate\" and constraint \"true_positive_rate_parity\"\n",
      "F1-score: 0.0\n",
      "Statistical parity: 0.0\n",
      "---\n",
      "Optimizing using objective \"accuracy_score\" and constraint \"true_negative_rate_parity\"\n",
      "F1-score: 0.06220095693779904\n",
      "Statistical parity: 0.0012246686948899094\n",
      "---\n",
      "Optimizing using objective \"balanced_accuracy_score\" and constraint \"true_negative_rate_parity\"\n",
      "F1-score: 0.38770226537216823\n",
      "Statistical parity: 0.002939204867735745\n",
      "---\n",
      "Optimizing using objective \"selection_rate\" and constraint \"true_negative_rate_parity\"\n",
      "F1-score: 0.2525399129172714\n",
      "Statistical parity: 0.0\n",
      "---\n",
      "Optimizing using objective \"true_positive_rate\" and constraint \"true_negative_rate_parity\"\n",
      "F1-score: 0.2525399129172714\n",
      "Statistical parity: 0.0\n",
      "---\n",
      "Optimizing using objective \"true_negative_rate\" and constraint \"true_negative_rate_parity\"\n",
      "F1-score: 0.0\n",
      "Statistical parity: 0.0\n",
      "---\n",
      "Optimizing using objective \"accuracy_score\" and constraint \"false_positive_rate_parity\"\n",
      "F1-score: 0.059808612440191394\n",
      "Statistical parity: 0.0020368174083432167\n",
      "---\n",
      "Optimizing using objective \"balanced_accuracy_score\" and constraint \"false_positive_rate_parity\"\n",
      "F1-score: 0.3880597014925373\n",
      "Statistical parity: 0.0006703449698344244\n",
      "---\n",
      "Optimizing using objective \"selection_rate\" and constraint \"false_positive_rate_parity\"\n",
      "F1-score: 0.2525399129172714\n",
      "Statistical parity: 0.0\n",
      "---\n",
      "Optimizing using objective \"true_positive_rate\" and constraint \"false_positive_rate_parity\"\n",
      "F1-score: 0.2525399129172714\n",
      "Statistical parity: 0.0\n",
      "---\n",
      "Optimizing using objective \"true_negative_rate\" and constraint \"false_positive_rate_parity\"\n",
      "F1-score: 0.0\n",
      "Statistical parity: 0.0\n",
      "---\n",
      "Optimizing using objective \"accuracy_score\" and constraint \"false_negative_rate_parity\"\n",
      "F1-score: 0.0\n",
      "Statistical parity: 0.0\n",
      "---\n",
      "Optimizing using objective \"balanced_accuracy_score\" and constraint \"false_negative_rate_parity\"\n",
      "F1-score: 0.3908196721311475\n",
      "Statistical parity: -0.009217243335224001\n",
      "---\n",
      "Optimizing using objective \"selection_rate\" and constraint \"false_negative_rate_parity\"\n",
      "F1-score: 0.2525399129172714\n",
      "Statistical parity: 0.0\n",
      "---\n",
      "Optimizing using objective \"true_positive_rate\" and constraint \"false_negative_rate_parity\"\n",
      "F1-score: 0.26002996504078574\n",
      "Statistical parity: -0.05501985252410668\n",
      "---\n",
      "Optimizing using objective \"true_negative_rate\" and constraint \"false_negative_rate_parity\"\n",
      "F1-score: 0.0\n",
      "Statistical parity: 0.0\n"
     ]
    }
   ],
   "source": [
    "possible_constraints = [\n",
    "    'demographic_parity',\n",
    "    'selection_rate_parity',\n",
    "    'equalized_odds',\n",
    "    'true_positive_rate_parity',\n",
    "    'true_negative_rate_parity',\n",
    "    'false_positive_rate_parity',\n",
    "    'false_negative_rate_parity',\n",
    "]\n",
    "possible_objectives = [\n",
    "    'accuracy_score',\n",
    "    'balanced_accuracy_score',\n",
    "    'selection_rate',\n",
    "    'true_positive_rate',\n",
    "    'true_negative_rate',\n",
    "]\n",
    "\n",
    "impossible_pairs = [\n",
    "  ['equalized_odds', 'selection_rate'],\n",
    "  ['equalized_odds', 'true_positive_rate'],\n",
    "  ['equalized_odds', 'true_negative_rate'],\n",
    "]\n",
    "\n",
    "results = dict()\n",
    "\n",
    "y_val_ = clf.predict(X_val)\n",
    "baseline_f1 = f1_score(y_val, y_val_)\n",
    "baseline_sp = statistical_parity(y_val, y_val_, Z_val)[0]\n",
    "print(f'Baseline F1: {baseline_f1}')\n",
    "print(f'Baseline statistical parity: {baseline_sp}')\n",
    "\n",
    "results['baseline']= [baseline_f1, baseline_sp]\n",
    "\n",
    "for constraint in possible_constraints:\n",
    "    for objective in possible_objectives:\n",
    "        if [constraint, objective] not in impossible_pairs:\n",
    "            print('---')\n",
    "            print(f'Optimizing using objective \"{objective}\" and constraint \"{constraint}\"')\n",
    "            postprocess_est = ThresholdOptimizer(\n",
    "                   estimator=clf,\n",
    "                   constraints=constraint,\n",
    "                   objective=objective,\n",
    "                   prefit=True,\n",
    "                   predict_method='predict_proba')\n",
    "            postprocess_est.fit(X_train, y_train, sensitive_features=Z_train)\n",
    "            \n",
    "            y_val_ = postprocess_est.predict(X_val, sensitive_features=Z_val)\n",
    "            alt_f1 = f1_score(y_val, y_val_)\n",
    "            alt_sp = statistical_parity(y_val, y_val_, Z_val)[0]\n",
    "            print(f'F1-score: {alt_f1}')\n",
    "            print(f'Statistical parity: {alt_sp}')\n",
    "            results[f'{objective}__{constraint}']= [alt_f1, alt_sp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73862e8f-7c98-425e-8980-5ebaf35739ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline': [0.38822387576835976, -0.030887433610065462],\n",
       " 'accuracy_score__demographic_parity': [0.06658739595719383,\n",
       "  0.0018305574176249156],\n",
       " 'balanced_accuracy_score__demographic_parity': [0.3863709418193507,\n",
       "  0.008894962099726678],\n",
       " 'selection_rate__demographic_parity': [0.2525399129172714, 0.0],\n",
       " 'true_positive_rate__demographic_parity': [0.2525399129172714, 0.0],\n",
       " 'true_negative_rate__demographic_parity': [0.0, 0.0],\n",
       " 'accuracy_score__selection_rate_parity': [0.06183115338882283,\n",
       "  0.0026427061310782245],\n",
       " 'balanced_accuracy_score__selection_rate_parity': [0.3875321336760925,\n",
       "  0.009178569586964336],\n",
       " 'selection_rate__selection_rate_parity': [0.2525399129172714, 0.0],\n",
       " 'true_positive_rate__selection_rate_parity': [0.2525399129172714, 0.0],\n",
       " 'true_negative_rate__selection_rate_parity': [0.0, 0.0],\n",
       " 'accuracy_score__equalized_odds': [0.0, 0.0],\n",
       " 'balanced_accuracy_score__equalized_odds': [0.3862382343395001,\n",
       "  0.0003867374825967662],\n",
       " 'accuracy_score__true_positive_rate_parity': [0.0, -0.0005285412262156448],\n",
       " 'balanced_accuracy_score__true_positive_rate_parity': [0.3906915765322845,\n",
       "  -0.009745784561439652],\n",
       " 'selection_rate__true_positive_rate_parity': [0.2525399129172714, 0.0],\n",
       " 'true_positive_rate__true_positive_rate_parity': [0.2525399129172714, 0.0],\n",
       " 'true_negative_rate__true_positive_rate_parity': [0.0, 0.0],\n",
       " 'accuracy_score__true_negative_rate_parity': [0.06220095693779904,\n",
       "  0.0012246686948899094],\n",
       " 'balanced_accuracy_score__true_negative_rate_parity': [0.38770226537216823,\n",
       "  0.002939204867735745],\n",
       " 'selection_rate__true_negative_rate_parity': [0.2525399129172714, 0.0],\n",
       " 'true_positive_rate__true_negative_rate_parity': [0.2525399129172714, 0.0],\n",
       " 'true_negative_rate__true_negative_rate_parity': [0.0, 0.0],\n",
       " 'accuracy_score__false_positive_rate_parity': [0.059808612440191394,\n",
       "  0.0020368174083432167],\n",
       " 'balanced_accuracy_score__false_positive_rate_parity': [0.3880597014925373,\n",
       "  0.0006703449698344244],\n",
       " 'selection_rate__false_positive_rate_parity': [0.2525399129172714, 0.0],\n",
       " 'true_positive_rate__false_positive_rate_parity': [0.2525399129172714, 0.0],\n",
       " 'true_negative_rate__false_positive_rate_parity': [0.0, 0.0],\n",
       " 'accuracy_score__false_negative_rate_parity': [0.0, 0.0],\n",
       " 'balanced_accuracy_score__false_negative_rate_parity': [0.3908196721311475,\n",
       "  -0.009217243335224001],\n",
       " 'selection_rate__false_negative_rate_parity': [0.2525399129172714, 0.0],\n",
       " 'true_positive_rate__false_negative_rate_parity': [0.26002996504078574,\n",
       "  -0.05501985252410668],\n",
       " 'true_negative_rate__false_negative_rate_parity': [0.0, 0.0]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a039590-c1f3-48d1-905c-4441caa6b4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best objetive: balanced_accuracy_score\n",
      "Best constraint: equalized_odds\n",
      "F1-score: 0.3862382343395001\n",
      "Statistical parity: 0.0003867374825967662\n"
     ]
    }
   ],
   "source": [
    "best_combination = 'baseline'\n",
    "best_combination_f1 = results[best_combination][0]\n",
    "best_combination_sp = results[best_combination][1]\n",
    "\n",
    "for combination, (alt_f1, alt_sp) in results.items():\n",
    "    # In some cases, the statistical-parity or f1-score is 0, we consider those as an error\n",
    "    # After this, we're checking if the candidate statistic parity is closer to 0 than the current best candidate\n",
    "    if alt_f1 != 0 and alt_sp != 0 and min((abs(x), x) for x in [alt_sp, best_combination_sp])[1] == alt_sp:\n",
    "        best_combination = combination\n",
    "        best_combination_f1 = alt_f1\n",
    "        best_combination_sp = alt_sp\n",
    "\n",
    "objective, constraint = best_combination.split('__')\n",
    "print(f'Best objetive: {objective}')\n",
    "print(f'Best constraint: {constraint}')\n",
    "print(f'F1-score: {best_combination_f1}')\n",
    "print(f'Statistical parity: {best_combination_sp}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fc1d54-66de-45b2-aca8-6f5c7b587fbf",
   "metadata": {},
   "source": [
    "## Estratégia 2: Leaf Relabelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262cdce6-fd52-4284-9a96-3b810547645f",
   "metadata": {},
   "source": [
    "Seguindo o que foi apresentado por [Kamiran et al.](https://www.win.tue.nl/~mpechen/publications/pubs/KamiranICDM2010.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70ecc361-8359-484d-8387-d0d35786c2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Leaf:\n",
    "    def __init__(self, path, node_id, u, v, w, x, transactions=None):\n",
    "        self.path = path\n",
    "        self.node_id = node_id\n",
    "        self.acc = None\n",
    "        self.disc = None\n",
    "        self.ratio = None\n",
    "        self.u = u\n",
    "        self.v = v\n",
    "        self.w = w\n",
    "        self.x = x\n",
    "        self.transactions = transactions\n",
    "\n",
    "    def compute_gain(self, cnt_p, cnt_n, portion_zero, portion_one):\n",
    "        n = self.u + self.w\n",
    "        p = self.v + self.x\n",
    "        \n",
    "        if cnt_p > cnt_n:\n",
    "            self.acc = n - p\n",
    "            self.disc = (self.u + self.v) / portion_one - (self.w + self.x) / portion_zero\n",
    "\n",
    "        else:\n",
    "            self.acc = p - n\n",
    "            self.disc = -(self.u + self.v) / portion_one + (self.w + self.x) / portion_zero\n",
    "\n",
    "        if self.acc == 0:\n",
    "            self.ratio = self.disc / -0.00000000000000000000000000000000000001\n",
    "        else:\n",
    "            self.ratio = self.disc / self.acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62f4993f-df7c-4ee5-be6c-1aabcb61b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel_leaves(clf, x, y, y_pred, sensitive, threshold):\n",
    "    for leaf in get_leaves_to_relabel(clf, x, y, y_pred, sensitive, threshold):\n",
    "        if clf.tree_.value[leaf.node_id][0][0] == clf.tree_.value[leaf.node_id][0][1]:\n",
    "            clf.tree_.value[leaf.node_id][0][1] += 1\n",
    "        else:\n",
    "            clf.tree_.value[leaf.node_id][0][0], clf.tree_.value[leaf.node_id][0][1] = \\\n",
    "                clf.tree_.value[leaf.node_id][0][1], clf.tree_.value[leaf.node_id][0][0]\n",
    "\n",
    "def get_leaves_to_relabel(clf, x, y, y_pred, sensitive, threshold):\n",
    "    disc_tree = discrimination(y, y_pred, sensitive)\n",
    "    cnt = np.unique(sensitive, return_counts=True)[1]\n",
    "\n",
    "    i = list()\n",
    "    get_leaves_candidates(clf, x, y, sensitive, cnt, len(y), i)\n",
    "    leaves = set()\n",
    "    \n",
    "    while rem_disc(disc_tree, leaves, threshold) > threshold and i:\n",
    "        best_l = i[0]\n",
    "        for leaf in i:\n",
    "            if leaf.ratio > best_l.ratio:\n",
    "                best_l = leaf\n",
    "        leaves.add(best_l)\n",
    "        i.remove(best_l)\n",
    "\n",
    "    return leaves\n",
    "\n",
    "def discrimination(y, y_pred, sensitive):\n",
    "    w2, x2, u2, v2, b, b_not = 0, 0, 0, 0, 0, 0\n",
    "    y_length = len(y)\n",
    "    for index in range(0, y_length):\n",
    "        if y_pred[index] == 1:\n",
    "            if sensitive[index] == 0:\n",
    "                if y[index] == 0:\n",
    "                    w2 += 1\n",
    "                elif y[index] == 1:\n",
    "                    x2 += 1\n",
    "            elif sensitive[index] == 1:\n",
    "                if y[index] == 0:\n",
    "                    u2 += 1\n",
    "                elif y[index] == 1:\n",
    "                    v2 += 1\n",
    "        if sensitive[index] == 1:\n",
    "            b += 1\n",
    "        elif sensitive[index] == 0:\n",
    "            b_not += 1\n",
    "\n",
    "    w2 = w2 / y_length\n",
    "    x2 = x2 / y_length\n",
    "    u2 = u2 / y_length\n",
    "    v2 = v2 / y_length\n",
    "\n",
    "    b = b / y_length\n",
    "    b_not = b_not / y_length\n",
    "\n",
    "    return ((w2 + x2) / b_not) - ((u2 + v2) / b)\n",
    "\n",
    "\n",
    "def get_leaves_candidates(clf, x, y, sensitive, cnt, length, leaves, node_id=0, path=tuple()):\n",
    "    feature = clf.tree_.feature[node_id]\n",
    "    if feature >= 0:\n",
    "        tmp_path = path + ((node_id, feature, 'left'),)\n",
    "        get_leaves_candidates(clf, x, y, sensitive, cnt, length, leaves,\n",
    "                              clf.tree_.children_left[node_id], tmp_path)\n",
    "        tmp_path = path + ((node_id, feature, 'right'),)\n",
    "        get_leaves_candidates(clf, x, y, sensitive, cnt, length, leaves,\n",
    "                              clf.tree_.children_right[node_id], tmp_path)\n",
    "    else:\n",
    "        transactions = get_transactions_by_leaf(clf, path, x)\n",
    "        tmp_path = path + ((node_id, feature, 'leaf'),)\n",
    "\n",
    "        u, v, w, x = 0, 0, 0, 0\n",
    "        for transaction in transactions:\n",
    "            if sensitive[transaction] == 1:\n",
    "                if y[transaction] == 0:\n",
    "                    u += 1\n",
    "                elif y[transaction] == 1:\n",
    "                    v += 1\n",
    "            elif sensitive[transaction] == 0:\n",
    "                if y[transaction] == 0:\n",
    "                    w += 1\n",
    "                elif y[transaction] == 1:\n",
    "                    x += 1\n",
    "        leaf = Leaf(tmp_path, node_id, u / length, v / length,\n",
    "                    w / length, x / length, transactions)\n",
    "        leaf.compute_gain(v + x, u + w, cnt[0] / length, cnt[1] / length)\n",
    "        if leaf.disc < 0:\n",
    "            leaves.append(leaf)\n",
    "            \n",
    "def get_transactions_by_leaf(clf, path, x):\n",
    "    filtered = pd.DataFrame(x)\n",
    "    for tupl in path:\n",
    "        node_id = tupl[0]\n",
    "        feature = tupl[1]\n",
    "        if tupl[2] == 'left':\n",
    "            filtered = filtered.loc[filtered[feature] <= clf.tree_.threshold[node_id]]\n",
    "        elif tupl[2] == 'right':\n",
    "            filtered = filtered.loc[filtered[feature] > clf.tree_.threshold[node_id]]\n",
    "        else:\n",
    "            raise Exception(\"Should not reach here\")\n",
    "    return list(filtered.index)\n",
    "\n",
    "def rem_disc(disc_tree, leaves, threshold):\n",
    "    s = 0\n",
    "    for leaf in leaves:\n",
    "        if leaf.disc < threshold:\n",
    "            s += leaf.disc\n",
    "    return disc_tree + s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8af46842-2448-4246-81d2-76c21bdd44d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lr = pd.read_csv('../../data/final_features_df.csv')\n",
    "df_lr.head()\n",
    "df_lr = df_lr.fillna(0)\n",
    "y_lr = df_lr['Rating_bin']\n",
    "X_lr = df.drop(columns=['Unnamed: 0', 'Rating_bin', 'Gender_M'])\n",
    "X_lr_train, X_lr_val, y_lr_train, y_lr_val = train_test_split(X_lr, y_lr, random_state=42, train_size=0.85)\n",
    "\n",
    "sensitive = X_lr_val['Gender_F']\n",
    "\n",
    "y_lr_np = y_lr_val.to_numpy()\n",
    "X_lr_np = X_lr_val.to_numpy()\n",
    "sensitive_np = sensitive.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fdd0f9c-9602-4bf8-a30e-f80cf1ac1eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(class_weight='balanced')\n",
    "clf.fit(X_lr_train, y_lr_train)\n",
    "\n",
    "y_lr_original_pred = clf.predict(X_lr_val)\n",
    "threshold = -0.0001\n",
    "\n",
    "relabel_leaves(clf, X_lr_np, y_lr_np, y_lr_original_pred, sensitive_np, threshold)\n",
    "y_lr_pred_relabeled = clf.predict(X_lr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0eac352-02a6-4db7-820f-38324e1bd77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.36596893990546925\n",
      "Statistical parity -0.04310833806012476\n"
     ]
    }
   ],
   "source": [
    "print('F1-score:', f1_score(y_lr_val, y_lr_pred_relabeled))\n",
    "print('Statistical parity', statistical_parity(y_lr_val, y_lr_pred_relabeled, Z_val)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d31e63ec9ea2e20ed3c82f8f8f09c9cfcb087848551707a33b558afb7dcb40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
