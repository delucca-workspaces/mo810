{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.algorithms.preprocessing import Reweighing, DisparateImpactRemover\n",
    "from aif360.metrics import BinaryLabelDatasetMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>faves_pca0</th>\n",
       "      <th>faves_pca1</th>\n",
       "      <th>unfaves_pca0</th>\n",
       "      <th>unfaves_pca1</th>\n",
       "      <th>accessories</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>animamted</th>\n",
       "      <th>...</th>\n",
       "      <th>Drama.2</th>\n",
       "      <th>Entertainment (Variety Shows)</th>\n",
       "      <th>Factual</th>\n",
       "      <th>Learning</th>\n",
       "      <th>Music</th>\n",
       "      <th>News</th>\n",
       "      <th>Religion &amp;amp; Ethics</th>\n",
       "      <th>Sport.1</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Rating_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321485</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>-0.19967</td>\n",
       "      <td>-0.200645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321485</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>-0.19967</td>\n",
       "      <td>-0.200645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321485</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>-0.19967</td>\n",
       "      <td>-0.200645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321485</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>-0.19967</td>\n",
       "      <td>-0.200645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321485</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>-0.19967</td>\n",
       "      <td>-0.200645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 515 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Age  Income  faves_pca0  faves_pca1  unfaves_pca0  \\\n",
       "0           0   62       1   -0.321485      0.0786      -0.19967   \n",
       "1           1   62       1   -0.321485      0.0786      -0.19967   \n",
       "2           2   62       1   -0.321485      0.0786      -0.19967   \n",
       "3           3   62       1   -0.321485      0.0786      -0.19967   \n",
       "4           4   62       1   -0.321485      0.0786      -0.19967   \n",
       "\n",
       "   unfaves_pca1  accessories  alcohol  animamted  ...  Drama.2  \\\n",
       "0     -0.200645          0.0      0.0        0.0  ...        1   \n",
       "1     -0.200645          0.0      0.0        0.0  ...        1   \n",
       "2     -0.200645          0.0      0.0        0.0  ...        1   \n",
       "3     -0.200645          0.0      0.0        0.0  ...        1   \n",
       "4     -0.200645          0.0      0.0        0.0  ...        1   \n",
       "\n",
       "   Entertainment (Variety Shows)  Factual  Learning  Music  News  \\\n",
       "0                              0        0         0      0     0   \n",
       "1                              0        0         0      0     0   \n",
       "2                              0        0         0      0     0   \n",
       "3                              0        0         0      0     0   \n",
       "4                              0        0         0      0     0   \n",
       "\n",
       "   Religion &amp; Ethics  Sport.1  Weather  Rating_bin  \n",
       "0                      0        0        0           0  \n",
       "1                      0        0        0           0  \n",
       "2                      0        0        0           0  \n",
       "3                      0        0        0           0  \n",
       "4                      0        0        0           0  \n",
       "\n",
       "[5 rows x 515 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/final_features_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{'Gender_M': 1}]\n",
    "unprivileged_groups = [{'Gender_M': 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    31279\n",
       "1     4841\n",
       "Name: Rating_bin, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0['Rating_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Age', 'Income', 'faves_pca0', 'faves_pca1',\n",
       "       'unfaves_pca0', 'unfaves_pca1', 'accessories', 'alcohol', 'animamted',\n",
       "       ...\n",
       "       'Drama.2', 'Entertainment (Variety Shows)', 'Factual', 'Learning',\n",
       "       'Music', 'News', 'Religion &amp; Ethics', 'Sport.1', 'Weather',\n",
       "       'Rating_bin'],\n",
       "      dtype='object', length=515)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "aif360_df = StandardDataset(\n",
    "    df = df_0.drop(['Gender_F', 'Unnamed: 0'], axis = 1),\n",
    "    label_name = 'Rating_bin',\n",
    "    protected_attribute_names = ['Gender_M'],\n",
    "    favorable_classes = [0],\n",
    "    privileged_classes = [df_0['Gender_M'], lambda x: x == 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = aif360_df.split([0.7], shuffle=True, seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = aif360_df.features\n",
    "y = aif360_df.labels\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Parity Difference between unprivileged and privileged groups in original dataset = 0.018700\n"
     ]
    }
   ],
   "source": [
    "metric_orig = BinaryLabelDatasetMetric(aif360_df, \n",
    "                                       unprivileged_groups=unprivileged_groups,\n",
    "                                       privileged_groups=privileged_groups,\n",
    "                                       )\n",
    "\n",
    "print(\"Statistical Parity Difference between unprivileged and privileged groups in original dataset = %f\" % metric_orig.statistical_parity_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conv = aif360_df.convert_to_dataframe()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25284, 513)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.convert_to_dataframe()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27090, 512)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected 27090 rows, received array of length 25284",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [41], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maif360\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m statistical_parity_difference\n\u001b[0;32m----> 2\u001b[0m statistical_parity_difference(y_train, y_train, prot_attr\u001b[39m=\u001b[39;49m df_train\u001b[39m.\u001b[39;49mconvert_to_dataframe()[\u001b[39m0\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mGender_M\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39;49m \u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/Unicamp/mo810/.venv/lib/python3.10/site-packages/aif360/sklearn/metrics/metrics.py:512\u001b[0m, in \u001b[0;36mstatistical_parity_difference\u001b[0;34m(y_true, y_pred, prot_attr, priv_group, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Difference in selection rates.\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \n\u001b[1;32m    485\u001b[0m \u001b[39m.. math::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[39m    :func:`selection_rate`, :func:`base_rate`\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    511\u001b[0m rate \u001b[39m=\u001b[39m base_rate \u001b[39mif\u001b[39;00m y_pred \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m selection_rate\n\u001b[0;32m--> 512\u001b[0m \u001b[39mreturn\u001b[39;00m difference(rate, y_true, y_pred, prot_attr\u001b[39m=\u001b[39;49mprot_attr,\n\u001b[1;32m    513\u001b[0m                   priv_group\u001b[39m=\u001b[39;49mpriv_group, pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m    514\u001b[0m                   sample_weight\u001b[39m=\u001b[39;49msample_weight)\n",
      "File \u001b[0;32m~/Unicamp/mo810/.venv/lib/python3.10/site-packages/aif360/sklearn/metrics/metrics.py:76\u001b[0m, in \u001b[0;36mdifference\u001b[0;34m(func, y_true, y_pred, prot_attr, priv_group, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdifference\u001b[39m(func, y_true, y_pred\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, prot_attr\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, priv_group\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     43\u001b[0m                sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     44\u001b[0m     \u001b[39m\"\"\"Compute the difference between unprivileged and privileged subsets for an\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39m    arbitrary metric.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39m        -0.06955430006277463\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     groups, _ \u001b[39m=\u001b[39m check_groups(y_true, prot_attr)\n\u001b[1;32m     77\u001b[0m     idx \u001b[39m=\u001b[39m (groups \u001b[39m==\u001b[39m priv_group)\n\u001b[1;32m     78\u001b[0m     unpriv \u001b[39m=\u001b[39m [y[\u001b[39m~\u001b[39midx] \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m (y_true, y_pred) \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m]\n",
      "File \u001b[0;32m~/Unicamp/mo810/.venv/lib/python3.10/site-packages/aif360/sklearn/utils.py:87\u001b[0m, in \u001b[0;36mcheck_groups\u001b[0;34m(arr, prot_attr, ensure_binary)\u001b[0m\n\u001b[1;32m     85\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(index\u001b[39m=\u001b[39m[\u001b[39mNone\u001b[39;00m]\u001b[39m*\u001b[39m\u001b[39mlen\u001b[39m(arr))  \u001b[39m# dummy to check lengths match\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m     groups \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mset_index(prot_attr)\u001b[39m.\u001b[39mindex\n\u001b[1;32m     88\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     89\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39marr does not include protected attributes in the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mindex. Check if this got dropped or prot_attr is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mformatted incorrectly.\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/Unicamp/mo810/.venv/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Unicamp/mo810/.venv/lib/python3.10/site-packages/pandas/core/frame.py:6059\u001b[0m, in \u001b[0;36mDataFrame.set_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   6054\u001b[0m             to_remove\u001b[39m.\u001b[39mappend(col)\n\u001b[1;32m   6056\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(arrays[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   6057\u001b[0m         \u001b[39m# check newest element against length of calling frame, since\u001b[39;00m\n\u001b[1;32m   6058\u001b[0m         \u001b[39m# ensure_index_from_sequences would not raise for append=False.\u001b[39;00m\n\u001b[0;32m-> 6059\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   6060\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLength mismatch: Expected \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m rows, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   6061\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreceived array of length \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(arrays[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   6062\u001b[0m         )\n\u001b[1;32m   6064\u001b[0m index \u001b[39m=\u001b[39m ensure_index_from_sequences(arrays, names)\n\u001b[1;32m   6066\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m index\u001b[39m.\u001b[39mis_unique:\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected 27090 rows, received array of length 25284"
     ]
    }
   ],
   "source": [
    "from aif360.sklearn.metrics import statistical_parity_difference\n",
    "statistical_parity_difference(y_train, y_train, prot_attr= df_train.convert_to_dataframe()[0]['Gender_M'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_parity(y, y_, Z, priv=None):\n",
    "  if priv is None:\n",
    "    values = np.unique(Z)\n",
    "    counts = [np.mean(y[Z==z]) for z in values]\n",
    "    priv = values[np.argmax(counts)]\n",
    "    unpriv = [z for z in values if z != priv]\n",
    "    print('Automatic priviledged value is', priv)\n",
    "  else:\n",
    "    unpriv = [z for z in values if z != priv]\n",
    "  \n",
    "  return np.array([np.mean([y_i for y_i, zi in zip(y_, Z) if zi == unp]) - np.mean([y_i for y_i, zi in zip(y_, Z) if zi == priv])\n",
    "                   for unp in unpriv])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 27090 but corresponding boolean dimension is 25284",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m statistical_parity(y_train, y_train, df_train\u001b[39m.\u001b[39;49mconvert_to_dataframe()[\u001b[39m0\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mGender_M\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "Cell \u001b[0;32mIn [46], line 4\u001b[0m, in \u001b[0;36mstatistical_parity\u001b[0;34m(y, y_, Z, priv)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mif\u001b[39;00m priv \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m   values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(Z)\n\u001b[0;32m----> 4\u001b[0m   counts \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mmean(y[Z\u001b[39m==\u001b[39mz]) \u001b[39mfor\u001b[39;00m z \u001b[39min\u001b[39;00m values]\n\u001b[1;32m      5\u001b[0m   priv \u001b[39m=\u001b[39m values[np\u001b[39m.\u001b[39margmax(counts)]\n\u001b[1;32m      6\u001b[0m   unpriv \u001b[39m=\u001b[39m [z \u001b[39mfor\u001b[39;00m z \u001b[39min\u001b[39;00m values \u001b[39mif\u001b[39;00m z \u001b[39m!=\u001b[39m priv]\n",
      "Cell \u001b[0;32mIn [46], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mif\u001b[39;00m priv \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m   values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(Z)\n\u001b[0;32m----> 4\u001b[0m   counts \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mmean(y[Z\u001b[39m==\u001b[39;49mz]) \u001b[39mfor\u001b[39;00m z \u001b[39min\u001b[39;00m values]\n\u001b[1;32m      5\u001b[0m   priv \u001b[39m=\u001b[39m values[np\u001b[39m.\u001b[39margmax(counts)]\n\u001b[1;32m      6\u001b[0m   unpriv \u001b[39m=\u001b[39m [z \u001b[39mfor\u001b[39;00m z \u001b[39min\u001b[39;00m values \u001b[39mif\u001b[39;00m z \u001b[39m!=\u001b[39m priv]\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 27090 but corresponding boolean dimension is 25284"
     ]
    }
   ],
   "source": [
    "statistical_parity(y_train, y_train, df_train.convert_to_dataframe()[0]['Gender_M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aif360_df.convert_to_dataframe().Gender_M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))\n",
    "confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.sklearn.metrics import statistical_parity_difference\n",
    "statistical_parity_difference(y_train, y_train, priv_group = 0, prot_attr = X_train['Gender_M'] == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "               privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW.fit(df_train)\n",
    "dataset_transf = RW.transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_transf.features\n",
    "y = dataset_transf.labels\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))\n",
    "confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_orig = BinaryLabelDatasetMetric(dataset_transf, \n",
    "                                       unprivileged_groups=unprivileged_groups,\n",
    "                                       privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Statistical Parity Difference between unprivileged and privileged groups in transformed dataset = %f\" % metric_orig.statistical_parity_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disparate Impact Remover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = DisparateImpactRemover(repair_level = 1.0)\n",
    "dataset_transf_train = di.fit_transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_transf_train.features\n",
    "y = dataset_transf_train.labels\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))\n",
    "confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_orig = BinaryLabelDatasetMetric(dataset_transf_train, \n",
    "                                       unprivileged_groups=unprivileged_groups,\n",
    "                                       privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Statistical Parity Difference between unprivileged and privileged groups in transformed dataset = %f\" % metric_orig.statistical_parity_difference())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d31e63ec9ea2e20ed3c82f8f8f09c9cfcb087848551707a33b558afb7dcb40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
