{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>faves_pca0</th>\n",
       "      <th>faves_pca1</th>\n",
       "      <th>unfaves_pca0</th>\n",
       "      <th>unfaves_pca1</th>\n",
       "      <th>accessories</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>animamted</th>\n",
       "      <th>...</th>\n",
       "      <th>Drama.2</th>\n",
       "      <th>Entertainment (Variety Shows)</th>\n",
       "      <th>Factual</th>\n",
       "      <th>Learning</th>\n",
       "      <th>Music</th>\n",
       "      <th>News</th>\n",
       "      <th>Religion &amp;amp; Ethics</th>\n",
       "      <th>Sport.1</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Rating_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321485</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>-0.19967</td>\n",
       "      <td>-0.200645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321485</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>-0.19967</td>\n",
       "      <td>-0.200645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321485</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>-0.19967</td>\n",
       "      <td>-0.200645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321485</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>-0.19967</td>\n",
       "      <td>-0.200645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321485</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>-0.19967</td>\n",
       "      <td>-0.200645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 515 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Age  Income  faves_pca0  faves_pca1  unfaves_pca0  \\\n",
       "0           0   62       1   -0.321485      0.0786      -0.19967   \n",
       "1           1   62       1   -0.321485      0.0786      -0.19967   \n",
       "2           2   62       1   -0.321485      0.0786      -0.19967   \n",
       "3           3   62       1   -0.321485      0.0786      -0.19967   \n",
       "4           4   62       1   -0.321485      0.0786      -0.19967   \n",
       "\n",
       "   unfaves_pca1  accessories  alcohol  animamted  ...  Drama.2  \\\n",
       "0     -0.200645          0.0      0.0        0.0  ...        1   \n",
       "1     -0.200645          0.0      0.0        0.0  ...        1   \n",
       "2     -0.200645          0.0      0.0        0.0  ...        1   \n",
       "3     -0.200645          0.0      0.0        0.0  ...        1   \n",
       "4     -0.200645          0.0      0.0        0.0  ...        1   \n",
       "\n",
       "   Entertainment (Variety Shows)  Factual  Learning  Music  News  \\\n",
       "0                              0        0         0      0     0   \n",
       "1                              0        0         0      0     0   \n",
       "2                              0        0         0      0     0   \n",
       "3                              0        0         0      0     0   \n",
       "4                              0        0         0      0     0   \n",
       "\n",
       "   Religion &amp; Ethics  Sport.1  Weather  Rating_bin  \n",
       "0                      0        0        0           0  \n",
       "1                      0        0        0           0  \n",
       "2                      0        0        0           0  \n",
       "3                      0        0        0           0  \n",
       "4                      0        0        0           0  \n",
       "\n",
       "[5 rows x 515 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/final_features_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_0.sample(frac = 1)\n",
    "# train_frac = 0.8\n",
    "# test_frac = 0.1\n",
    "\n",
    "# X_train = df[[c for c in df.columns if c != 'Rating_bin']].iloc[:int(len(df) * train_frac)].values\n",
    "# y_train = df.Rating_bin.iloc[:int(len(df) * train_frac)].values\n",
    "\n",
    "# X_test = df[[c for c in df.columns if c != 'Rating_bin']].iloc[int(len(df) * train_frac):int(len(df) * (train_frac+test_frac))].values\n",
    "# y_test = df.Rating_bin.iloc[int(len(df) * train_frac):int(len(df) * (train_frac+test_frac))].values\n",
    "\n",
    "# X_valid = df[[c for c in df.columns if c != 'Rating_bin']].iloc[int(len(df) * (train_frac+test_frac)):].values\n",
    "# y_valid = df.Rating_bin.iloc[int(len(df) * (train_frac+test_frac)):].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(X_train).to_csv('../../data/X_train.csv')\n",
    "# pd.DataFrame(y_train).to_csv('../../data/y_train.csv')\n",
    "\n",
    "# pd.DataFrame(X_test).to_csv('../../data/X_test.csv')\n",
    "# pd.DataFrame(y_test).to_csv('../../data/y_test.csv')\n",
    "\n",
    "# pd.DataFrame(X_valid).to_csv('../../data/X_valid.csv')\n",
    "# pd.DataFrame(y_valid).to_csv('../../data/y_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_0.drop(columns='Rating_bin')\n",
    "y = df_0['Rating_bin']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9030, 515)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_test = X_val.copy()\n",
    "actual_test['true_Rating_bin'] = y_val\n",
    "actual_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspired by: https://github.com/bryantruong/examingBiasInAI/blob/main/biasInMachineLearning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_df = actual_test[actual_test['Gender_M'] == 1]\n",
    "num_of_priviliged = male_df.shape[0]\n",
    "female_df = actual_test[actual_test['Gender_M'] == 0]\n",
    "num_of_unpriviliged = female_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13474081702711982"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpriviliged_outcomes = female_df[female_df['true_Rating_bin'] == 1].shape[0]\n",
    "unpriviliged_ratio = unpriviliged_outcomes/num_of_unpriviliged\n",
    "unpriviliged_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1466916354556804"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priviliged_outcomes = male_df[male_df['true_Rating_bin'] == 1].shape[0]\n",
    "priviliged_ratio = priviliged_outcomes/num_of_priviliged\n",
    "priviliged_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact, Sex vs. Rating: 0.91853101649977\n"
     ]
    }
   ],
   "source": [
    "# Calculating disparate impact\n",
    "disparate_impact = unpriviliged_ratio / priviliged_ratio\n",
    "print(\"Disparate Impact, Sex vs. Rating: \" + str(disparate_impact))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90      7775\n",
      "           1       0.40      0.39      0.39      1255\n",
      "\n",
      "    accuracy                           0.83      9030\n",
      "   macro avg       0.65      0.65      0.65      9030\n",
      "weighted avg       0.83      0.83      0.83      9030\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7047,  728],\n",
       "       [ 769,  486]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))\n",
    "confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_val)\n",
    "x_test_orig = X_val.copy()\n",
    "x_test_orig['pred_baseline'] = y_pred\n",
    "baseline_output = x_test_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_df = baseline_output[baseline_output['Gender_M'] == 1]\n",
    "num_of_priviliged = male_df.shape[0]\n",
    "female_df = baseline_output[baseline_output['Gender_M'] == 0]\n",
    "num_of_unpriviliged = female_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12615859938208032"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpriviliged_outcomes = female_df[female_df['pred_baseline'] == 1].shape[0]\n",
    "unpriviliged_ratio = unpriviliged_outcomes/num_of_unpriviliged\n",
    "unpriviliged_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14950062421972535"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priviliged_outcomes = male_df[male_df['pred_baseline'] == 1].shape[0]\n",
    "priviliged_ratio = priviliged_outcomes/num_of_priviliged\n",
    "priviliged_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact, Sex vs. Predicted Rating: 0.8438667065139569\n"
     ]
    }
   ],
   "source": [
    "# Calculating disparate impact\n",
    "disparate_impact = unpriviliged_ratio / priviliged_ratio\n",
    "print(\"Disparate Impact, Sex vs. Predicted Rating: \" + str(disparate_impact))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n"
     ]
    }
   ],
   "source": [
    "from aif360.datasets import StandardDataset\n",
    "from aif360.algorithms.preprocessing import Reweighing, DisparateImpactRemover\n",
    "from aif360.metrics import BinaryLabelDatasetMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{'Gender_M': 1}]\n",
    "unprivileged_groups = [{'Gender_M': 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    31279\n",
       "1     4841\n",
       "Name: Rating_bin, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0['Rating_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "aif360_df = StandardDataset(\n",
    "    df = df_0.drop('Gender_F', axis = 1),\n",
    "    label_name = 'Rating_bin',\n",
    "    protected_attribute_names = ['Gender_M'],\n",
    "    favorable_classes = [0],\n",
    "    privileged_classes = [df_0['Gender_M'], lambda x: x == 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = aif360_df.split([0.7], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "               privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW.fit(df_train)\n",
    "dataset_transf = RW.transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_transf.features\n",
    "y = dataset_transf.labels\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.91      0.91      5499\n",
      "         1.0       0.39      0.39      0.39       822\n",
      "\n",
      "    accuracy                           0.84      6321\n",
      "   macro avg       0.65      0.65      0.65      6321\n",
      "weighted avg       0.84      0.84      0.84      6321\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5004,  495],\n",
       "       [ 505,  317]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))\n",
    "confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups in original dataset = 0.012661\n"
     ]
    }
   ],
   "source": [
    "metric_orig = BinaryLabelDatasetMetric(df_train, \n",
    "                                       unprivileged_groups=unprivileged_groups,\n",
    "                                       privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups in original dataset = %f\" % metric_orig.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups in transformed dataset = 0.000000\n"
     ]
    }
   ],
   "source": [
    "metric_orig = BinaryLabelDatasetMetric(dataset_transf, \n",
    "                                       unprivileged_groups=unprivileged_groups,\n",
    "                                       privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups in transformed dataset = %f\" % metric_orig.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disparate Impact Remover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = DisparateImpactRemover(repair_level = 1.0)\n",
    "dataset_transf_train = di.fit_transform(df_train)\n",
    "transformed = dataset_transf_train.convert_to_dataframe()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_transf_train.features\n",
    "y = dataset_transf_train.labels\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.91      0.91      5499\n",
      "         1.0       0.40      0.38      0.39       822\n",
      "\n",
      "    accuracy                           0.85      6321\n",
      "   macro avg       0.65      0.65      0.65      6321\n",
      "weighted avg       0.84      0.85      0.84      6321\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5031,  468],\n",
       "       [ 509,  313]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))\n",
    "confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = transformed.drop('Rating_bin', axis = 1)\n",
    "y = transformed['Rating_bin']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliatessler/Unicamp/mo810/.venv/lib/python3.10/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "x_test_transf = X_val.copy()\n",
    "y_pred = clf.predict(X_val)\n",
    "x_test_transf['pred_model'] = y_pred\n",
    "model_output = x_test_transf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_df = model_output[model_output['Gender_M'] == 1]\n",
    "n_priviledged = male_df.shape[0]\n",
    "\n",
    "female_df = model_output[model_output['Gender_M'] == 0]\n",
    "n_unpriviledged = female_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08067284586337109"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpriviliged_outcomes = female_df[female_df['pred_model'] == 1].shape[0]\n",
    "unpriviliged_ratio = unpriviliged_outcomes/num_of_unpriviliged\n",
    "unpriviliged_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact, Sex vs. model output: 0.5396154449817139\n"
     ]
    }
   ],
   "source": [
    "disparate_impact = unpriviliged_ratio / priviliged_ratio\n",
    "print(\"Disparate Impact, Sex vs. model output: \" + str(disparate_impact))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d31e63ec9ea2e20ed3c82f8f8f09c9cfcb087848551707a33b558afb7dcb40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
